{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df = pd.read_csv('files/cyberbullying_tweets.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df = pd.get_dummies(df, columns = ['cyberbullying_type'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "new_cols = ['tweet_text', 'age','ethnicity','gender','not_cyberbullying','other_cyberbullying','religion']\n",
    "df.columns = new_cols"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## For a binary classifier, we just need to know what is cyberbullying, and what's not cyberbullying"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df = df.drop(columns = ['age','ethnicity','gender','other_cyberbullying','religion'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## I'd prefer to have my target be something that evaluates True for potentially harmful, not for 'not cyberbullying', so I'm going to switch that up."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df['potentially_harmful'] = [int(not val) for val in df['not_cyberbullying']]\n",
    "df = df.drop(columns = ['not_cyberbullying'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## I'm going to see if I can get away with not lemmatizing when I preprocess the text, because it would take ages to run this, and I'm doing this all on my local machine."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from data_preprocessing.preprocess_text import pre_process_text\n",
    "import tqdm\n",
    "\n",
    "df['tweet_text'] = [pre_process_text(text, lemmatizer = 'False') for text in tqdm.tqdm(df['tweet_text'])]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/sangersteel/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sangersteel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "symbols:  ['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', '®', '\\t', '\\n', '\\r']\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 47692/47692 [00:02<00:00, 16394.37it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "df = df.sample(frac=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              tweet_text  potentially_harmful\n",
       "9227   throw bum show single fortune company call you...                    1\n",
       "21246  tweet directed commie muslim men looking like ...                    1\n",
       "4109   halalfam biebervalue greenlinerzjm going block...                    0\n",
       "42184  el p weak az fuck big words uses makes look du...                    1\n",
       "598                             woo wait see happens mkr                    0\n",
       "...                                                  ...                  ...\n",
       "26297  legal advice common sense help people know say...                    1\n",
       "30832  looks like interesting night mkr http co doncc...                    1\n",
       "3345                  need skype verification keybase io                    0\n",
       "7041              pickaxe new crowbar http co bcspxtotge                    0\n",
       "8234   big nicca rape sat seat skool jokes doe gay ea...                    1\n",
       "\n",
       "[47692 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>potentially_harmful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9227</th>\n",
       "      <td>throw bum show single fortune company call you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21246</th>\n",
       "      <td>tweet directed commie muslim men looking like ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4109</th>\n",
       "      <td>halalfam biebervalue greenlinerzjm going block...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42184</th>\n",
       "      <td>el p weak az fuck big words uses makes look du...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>woo wait see happens mkr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26297</th>\n",
       "      <td>legal advice common sense help people know say...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30832</th>\n",
       "      <td>looks like interesting night mkr http co doncc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3345</th>\n",
       "      <td>need skype verification keybase io</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7041</th>\n",
       "      <td>pickaxe new crowbar http co bcspxtotge</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8234</th>\n",
       "      <td>big nicca rape sat seat skool jokes doe gay ea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47692 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "x = df['tweet_text']\n",
    "y = df['potentially_harmful']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow\n",
    "\n",
    "def build_model(max_tokens, max_len, dropout):\n",
    "\n",
    "    vectorize_layer = TextVectorization(\n",
    "        max_tokens=max_tokens,\n",
    "        output_mode=\"int\",\n",
    "        output_sequence_length=max_len,\n",
    "    )\n",
    "    vectorize_layer.adapt(x)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1,), dtype=tensorflow.string))   ## <=== enable str inputs\n",
    "    model.add(vectorize_layer)    ## <==== add TextVectorization inside Sequential\n",
    "    model.add(Embedding(max_tokens + 1, 128))\n",
    "    model.add(LSTM(64, dropout=dropout, recurrent_dropout=dropout))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model   "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "param_grid = {\n",
    "    \"max_tokens\" : [100,1000],\n",
    "    \"max_len\" : [10,100],\n",
    "    \"dropout\" : [0.1, 0.2],\n",
    "    \"epochs\" : [3,6]\n",
    "}\n",
    "model = GridSearchCV(KerasClassifier(build_model), param_grid, cv=3, scoring='accuracy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "model.fit(x_train, y_train, verbose=2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2022-02-03 16:46:12.600737: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "795/795 - 6s - loss: 0.3367 - accuracy: 0.8449 - 6s/epoch - 8ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 6s - loss: 0.3145 - accuracy: 0.8537 - 6s/epoch - 7ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 6s - loss: 0.3124 - accuracy: 0.8544 - 6s/epoch - 7ms/step\n",
      "Epoch 1/3\n",
      "795/795 - 6s - loss: 0.3406 - accuracy: 0.8462 - 6s/epoch - 8ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 5s - loss: 0.3176 - accuracy: 0.8546 - 5s/epoch - 7ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 6s - loss: 0.3150 - accuracy: 0.8546 - 6s/epoch - 7ms/step\n",
      "Epoch 1/3\n",
      "795/795 - 6s - loss: 0.3394 - accuracy: 0.8457 - 6s/epoch - 8ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 6s - loss: 0.3149 - accuracy: 0.8550 - 6s/epoch - 7ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 6s - loss: 0.3117 - accuracy: 0.8554 - 6s/epoch - 7ms/step\n",
      "Epoch 1/3\n",
      "795/795 - 7s - loss: 0.3212 - accuracy: 0.8532 - 7s/epoch - 9ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 5s - loss: 0.2797 - accuracy: 0.8644 - 5s/epoch - 7ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 6s - loss: 0.2666 - accuracy: 0.8716 - 6s/epoch - 7ms/step\n",
      "Epoch 1/3\n",
      "795/795 - 6s - loss: 0.3210 - accuracy: 0.8524 - 6s/epoch - 8ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 5s - loss: 0.2832 - accuracy: 0.8635 - 5s/epoch - 7ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 5s - loss: 0.2711 - accuracy: 0.8690 - 5s/epoch - 7ms/step\n",
      "Epoch 1/3\n",
      "795/795 - 8s - loss: 0.3227 - accuracy: 0.8529 - 8s/epoch - 10ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 7s - loss: 0.2796 - accuracy: 0.8641 - 7s/epoch - 9ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 7s - loss: 0.2680 - accuracy: 0.8723 - 7s/epoch - 9ms/step\n",
      "Epoch 1/3\n",
      "795/795 - 54s - loss: 0.4554 - accuracy: 0.8333 - 54s/epoch - 69ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 56s - loss: 0.4511 - accuracy: 0.8336 - 56s/epoch - 71ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 51s - loss: 0.4514 - accuracy: 0.8336 - 51s/epoch - 64ms/step\n",
      "Epoch 1/3\n",
      "795/795 - 52s - loss: 0.4537 - accuracy: 0.8340 - 52s/epoch - 65ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 61s - loss: 0.4504 - accuracy: 0.8340 - 61s/epoch - 76ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 51s - loss: 0.4501 - accuracy: 0.8340 - 51s/epoch - 65ms/step\n",
      "Epoch 1/3\n",
      "795/795 - 53s - loss: 0.4539 - accuracy: 0.8332 - 53s/epoch - 66ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 54s - loss: 0.4502 - accuracy: 0.8342 - 54s/epoch - 68ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 51s - loss: 0.4500 - accuracy: 0.8342 - 51s/epoch - 64ms/step\n",
      "Epoch 1/3\n",
      "795/795 - 56s - loss: 0.4537 - accuracy: 0.8328 - 56s/epoch - 71ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 51s - loss: 0.4513 - accuracy: 0.8336 - 51s/epoch - 65ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 51s - loss: 0.4506 - accuracy: 0.8336 - 51s/epoch - 64ms/step\n",
      "Epoch 1/3\n",
      "795/795 - 52s - loss: 0.4527 - accuracy: 0.8340 - 52s/epoch - 66ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 52s - loss: 0.4505 - accuracy: 0.8340 - 52s/epoch - 65ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 51s - loss: 0.4502 - accuracy: 0.8340 - 51s/epoch - 64ms/step\n",
      "Epoch 1/3\n",
      "795/795 - 51s - loss: 0.4529 - accuracy: 0.8340 - 51s/epoch - 65ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 51s - loss: 0.4505 - accuracy: 0.8342 - 51s/epoch - 64ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 50s - loss: 0.4503 - accuracy: 0.8342 - 50s/epoch - 63ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 6s - loss: 0.3400 - accuracy: 0.8443 - 6s/epoch - 8ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 5s - loss: 0.3153 - accuracy: 0.8543 - 5s/epoch - 7ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 5s - loss: 0.3129 - accuracy: 0.8541 - 5s/epoch - 7ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 5s - loss: 0.3095 - accuracy: 0.8549 - 5s/epoch - 7ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 5s - loss: 0.3089 - accuracy: 0.8545 - 5s/epoch - 7ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 6s - loss: 0.3081 - accuracy: 0.8539 - 6s/epoch - 7ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 7s - loss: 0.3374 - accuracy: 0.8479 - 7s/epoch - 8ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 6s - loss: 0.3170 - accuracy: 0.8547 - 6s/epoch - 8ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 5s - loss: 0.3158 - accuracy: 0.8548 - 5s/epoch - 7ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 5s - loss: 0.3135 - accuracy: 0.8545 - 5s/epoch - 7ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 5s - loss: 0.3121 - accuracy: 0.8555 - 5s/epoch - 7ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 5s - loss: 0.3104 - accuracy: 0.8546 - 5s/epoch - 7ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 6s - loss: 0.3369 - accuracy: 0.8473 - 6s/epoch - 8ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 5s - loss: 0.3155 - accuracy: 0.8545 - 5s/epoch - 7ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 5s - loss: 0.3141 - accuracy: 0.8550 - 5s/epoch - 7ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 5s - loss: 0.3114 - accuracy: 0.8554 - 5s/epoch - 7ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 5s - loss: 0.3103 - accuracy: 0.8557 - 5s/epoch - 7ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 5s - loss: 0.3084 - accuracy: 0.8559 - 5s/epoch - 7ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 6s - loss: 0.3212 - accuracy: 0.8500 - 6s/epoch - 8ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 6s - loss: 0.2808 - accuracy: 0.8653 - 6s/epoch - 7ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 6s - loss: 0.2675 - accuracy: 0.8705 - 6s/epoch - 7ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 6s - loss: 0.2556 - accuracy: 0.8772 - 6s/epoch - 7ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 6s - loss: 0.2455 - accuracy: 0.8790 - 6s/epoch - 7ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 6s - loss: 0.2340 - accuracy: 0.8857 - 6s/epoch - 7ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 7s - loss: 0.3238 - accuracy: 0.8523 - 7s/epoch - 9ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 7s - loss: 0.2841 - accuracy: 0.8635 - 7s/epoch - 9ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 6s - loss: 0.2709 - accuracy: 0.8687 - 6s/epoch - 8ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 6s - loss: 0.2612 - accuracy: 0.8725 - 6s/epoch - 7ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 5s - loss: 0.2493 - accuracy: 0.8781 - 5s/epoch - 7ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 6s - loss: 0.2381 - accuracy: 0.8844 - 6s/epoch - 8ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 7s - loss: 0.3223 - accuracy: 0.8523 - 7s/epoch - 9ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 6s - loss: 0.2804 - accuracy: 0.8653 - 6s/epoch - 7ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 6s - loss: 0.2669 - accuracy: 0.8707 - 6s/epoch - 8ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 6s - loss: 0.2572 - accuracy: 0.8750 - 6s/epoch - 7ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 6s - loss: 0.2469 - accuracy: 0.8799 - 6s/epoch - 7ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 6s - loss: 0.2379 - accuracy: 0.8847 - 6s/epoch - 7ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 53s - loss: 0.4547 - accuracy: 0.8333 - 53s/epoch - 66ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 51s - loss: 0.4514 - accuracy: 0.8336 - 51s/epoch - 64ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 51s - loss: 0.4512 - accuracy: 0.8336 - 51s/epoch - 65ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 52s - loss: 0.4511 - accuracy: 0.8336 - 52s/epoch - 65ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 53s - loss: 0.4508 - accuracy: 0.8336 - 53s/epoch - 66ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 51s - loss: 0.4510 - accuracy: 0.8336 - 51s/epoch - 64ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 51s - loss: 0.4542 - accuracy: 0.8330 - 51s/epoch - 65ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 50s - loss: 0.4504 - accuracy: 0.8340 - 50s/epoch - 63ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 51s - loss: 0.4500 - accuracy: 0.8340 - 51s/epoch - 64ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 50s - loss: 0.4503 - accuracy: 0.8340 - 50s/epoch - 63ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 50s - loss: 0.4502 - accuracy: 0.8340 - 50s/epoch - 63ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 52s - loss: 0.4500 - accuracy: 0.8340 - 52s/epoch - 65ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 51s - loss: 0.4534 - accuracy: 0.8331 - 51s/epoch - 64ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 50s - loss: 0.4505 - accuracy: 0.8342 - 50s/epoch - 64ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 51s - loss: 0.4499 - accuracy: 0.8342 - 51s/epoch - 64ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 50s - loss: 0.4501 - accuracy: 0.8342 - 50s/epoch - 63ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 50s - loss: 0.4499 - accuracy: 0.8342 - 50s/epoch - 63ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 51s - loss: 0.4499 - accuracy: 0.8342 - 51s/epoch - 64ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 51s - loss: 0.4548 - accuracy: 0.8336 - 51s/epoch - 65ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 50s - loss: 0.4513 - accuracy: 0.8336 - 50s/epoch - 64ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 51s - loss: 0.4510 - accuracy: 0.8336 - 51s/epoch - 64ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 51s - loss: 0.4510 - accuracy: 0.8336 - 51s/epoch - 64ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 51s - loss: 0.4512 - accuracy: 0.8336 - 51s/epoch - 64ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 51s - loss: 0.4509 - accuracy: 0.8336 - 51s/epoch - 64ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 52s - loss: 0.4533 - accuracy: 0.8340 - 52s/epoch - 65ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 50s - loss: 0.4508 - accuracy: 0.8340 - 50s/epoch - 63ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 51s - loss: 0.4501 - accuracy: 0.8341 - 51s/epoch - 64ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 51s - loss: 0.4504 - accuracy: 0.8341 - 51s/epoch - 64ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 51s - loss: 0.4499 - accuracy: 0.8341 - 51s/epoch - 64ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 51s - loss: 0.4499 - accuracy: 0.8341 - 51s/epoch - 64ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 51s - loss: 0.4537 - accuracy: 0.8336 - 51s/epoch - 64ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 50s - loss: 0.4504 - accuracy: 0.8342 - 50s/epoch - 63ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 50s - loss: 0.4504 - accuracy: 0.8343 - 50s/epoch - 63ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 51s - loss: 0.4501 - accuracy: 0.8342 - 51s/epoch - 64ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 51s - loss: 0.4497 - accuracy: 0.8343 - 51s/epoch - 64ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 51s - loss: 0.4497 - accuracy: 0.8343 - 51s/epoch - 64ms/step\n",
      "Epoch 1/3\n",
      "795/795 - 6s - loss: 0.3350 - accuracy: 0.8475 - 6s/epoch - 8ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 5s - loss: 0.3148 - accuracy: 0.8536 - 5s/epoch - 7ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 5s - loss: 0.3128 - accuracy: 0.8536 - 5s/epoch - 7ms/step\n",
      "Epoch 1/3\n",
      "795/795 - 6s - loss: 0.3406 - accuracy: 0.8474 - 6s/epoch - 8ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 5s - loss: 0.3189 - accuracy: 0.8530 - 5s/epoch - 7ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 5s - loss: 0.3163 - accuracy: 0.8545 - 5s/epoch - 7ms/step\n",
      "Epoch 1/3\n",
      "795/795 - 6s - loss: 0.3372 - accuracy: 0.8475 - 6s/epoch - 8ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 5s - loss: 0.3159 - accuracy: 0.8543 - 5s/epoch - 7ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 5s - loss: 0.3138 - accuracy: 0.8546 - 5s/epoch - 7ms/step\n",
      "Epoch 1/3\n",
      "795/795 - 6s - loss: 0.3216 - accuracy: 0.8500 - 6s/epoch - 8ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 6s - loss: 0.2808 - accuracy: 0.8640 - 6s/epoch - 7ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 6s - loss: 0.2687 - accuracy: 0.8712 - 6s/epoch - 7ms/step\n",
      "Epoch 1/3\n",
      "795/795 - 6s - loss: 0.3242 - accuracy: 0.8512 - 6s/epoch - 8ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 6s - loss: 0.2840 - accuracy: 0.8637 - 6s/epoch - 7ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 6s - loss: 0.2730 - accuracy: 0.8686 - 6s/epoch - 7ms/step\n",
      "Epoch 1/3\n",
      "795/795 - 7s - loss: 0.3237 - accuracy: 0.8515 - 7s/epoch - 8ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 6s - loss: 0.2833 - accuracy: 0.8643 - 6s/epoch - 7ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 5s - loss: 0.2696 - accuracy: 0.8712 - 5s/epoch - 7ms/step\n",
      "Epoch 1/3\n",
      "795/795 - 51s - loss: 0.4542 - accuracy: 0.8326 - 51s/epoch - 64ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 50s - loss: 0.4512 - accuracy: 0.8336 - 50s/epoch - 63ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 50s - loss: 0.4511 - accuracy: 0.8336 - 50s/epoch - 63ms/step\n",
      "Epoch 1/3\n",
      "795/795 - 51s - loss: 0.4537 - accuracy: 0.8340 - 51s/epoch - 64ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 50s - loss: 0.4516 - accuracy: 0.8340 - 50s/epoch - 63ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 50s - loss: 0.4504 - accuracy: 0.8340 - 50s/epoch - 63ms/step\n",
      "Epoch 1/3\n",
      "795/795 - 51s - loss: 0.4543 - accuracy: 0.8336 - 51s/epoch - 64ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 50s - loss: 0.4505 - accuracy: 0.8342 - 50s/epoch - 63ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 50s - loss: 0.4501 - accuracy: 0.8342 - 50s/epoch - 63ms/step\n",
      "Epoch 1/3\n",
      "795/795 - 52s - loss: 0.4545 - accuracy: 0.8335 - 52s/epoch - 65ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 50s - loss: 0.4516 - accuracy: 0.8336 - 50s/epoch - 63ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 50s - loss: 0.4512 - accuracy: 0.8336 - 50s/epoch - 63ms/step\n",
      "Epoch 1/3\n",
      "795/795 - 51s - loss: 0.4541 - accuracy: 0.8340 - 51s/epoch - 64ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 50s - loss: 0.4504 - accuracy: 0.8340 - 50s/epoch - 63ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 51s - loss: 0.4503 - accuracy: 0.8341 - 51s/epoch - 64ms/step\n",
      "Epoch 1/3\n",
      "795/795 - 53s - loss: 0.4530 - accuracy: 0.8337 - 53s/epoch - 67ms/step\n",
      "Epoch 2/3\n",
      "795/795 - 50s - loss: 0.4502 - accuracy: 0.8342 - 50s/epoch - 63ms/step\n",
      "Epoch 3/3\n",
      "795/795 - 50s - loss: 0.4504 - accuracy: 0.8342 - 50s/epoch - 63ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 6s - loss: 0.3368 - accuracy: 0.8452 - 6s/epoch - 8ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 5s - loss: 0.3144 - accuracy: 0.8539 - 5s/epoch - 7ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 5s - loss: 0.3118 - accuracy: 0.8546 - 5s/epoch - 7ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 5s - loss: 0.3109 - accuracy: 0.8544 - 5s/epoch - 7ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 5s - loss: 0.3094 - accuracy: 0.8542 - 5s/epoch - 6ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 5s - loss: 0.3074 - accuracy: 0.8549 - 5s/epoch - 7ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 6s - loss: 0.3380 - accuracy: 0.8480 - 6s/epoch - 8ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 5s - loss: 0.3185 - accuracy: 0.8530 - 5s/epoch - 6ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 5s - loss: 0.3154 - accuracy: 0.8547 - 5s/epoch - 6ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 5s - loss: 0.3141 - accuracy: 0.8554 - 5s/epoch - 6ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 5s - loss: 0.3126 - accuracy: 0.8550 - 5s/epoch - 6ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 5s - loss: 0.3114 - accuracy: 0.8553 - 5s/epoch - 6ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 6s - loss: 0.3414 - accuracy: 0.8469 - 6s/epoch - 7ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 5s - loss: 0.3153 - accuracy: 0.8548 - 5s/epoch - 6ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 5s - loss: 0.3131 - accuracy: 0.8552 - 5s/epoch - 6ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 5s - loss: 0.3122 - accuracy: 0.8556 - 5s/epoch - 6ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 5s - loss: 0.3104 - accuracy: 0.8551 - 5s/epoch - 7ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 5s - loss: 0.3091 - accuracy: 0.8557 - 5s/epoch - 6ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 6s - loss: 0.3199 - accuracy: 0.8518 - 6s/epoch - 8ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 5s - loss: 0.2817 - accuracy: 0.8635 - 5s/epoch - 7ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 5s - loss: 0.2695 - accuracy: 0.8688 - 5s/epoch - 7ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 5s - loss: 0.2568 - accuracy: 0.8756 - 5s/epoch - 7ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 5s - loss: 0.2455 - accuracy: 0.8818 - 5s/epoch - 7ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 5s - loss: 0.2352 - accuracy: 0.8840 - 5s/epoch - 7ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 6s - loss: 0.3244 - accuracy: 0.8498 - 6s/epoch - 8ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 6s - loss: 0.2838 - accuracy: 0.8627 - 6s/epoch - 7ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 5s - loss: 0.2724 - accuracy: 0.8681 - 5s/epoch - 7ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 5s - loss: 0.2603 - accuracy: 0.8740 - 5s/epoch - 7ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 5s - loss: 0.2520 - accuracy: 0.8766 - 5s/epoch - 7ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 6s - loss: 0.2395 - accuracy: 0.8830 - 6s/epoch - 7ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 6s - loss: 0.3222 - accuracy: 0.8533 - 6s/epoch - 8ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 5s - loss: 0.2815 - accuracy: 0.8655 - 5s/epoch - 7ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 5s - loss: 0.2681 - accuracy: 0.8721 - 5s/epoch - 7ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 6s - loss: 0.2586 - accuracy: 0.8741 - 6s/epoch - 8ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 6s - loss: 0.2481 - accuracy: 0.8795 - 6s/epoch - 7ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 6s - loss: 0.2392 - accuracy: 0.8833 - 6s/epoch - 7ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 51s - loss: 0.4541 - accuracy: 0.8336 - 51s/epoch - 64ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 50s - loss: 0.4515 - accuracy: 0.8336 - 50s/epoch - 63ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 50s - loss: 0.4512 - accuracy: 0.8336 - 50s/epoch - 63ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 50s - loss: 0.4511 - accuracy: 0.8336 - 50s/epoch - 63ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 50s - loss: 0.4506 - accuracy: 0.8336 - 50s/epoch - 62ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 50s - loss: 0.4508 - accuracy: 0.8336 - 50s/epoch - 62ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 51s - loss: 0.4531 - accuracy: 0.8340 - 51s/epoch - 64ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 50s - loss: 0.4503 - accuracy: 0.8340 - 50s/epoch - 63ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 50s - loss: 0.4503 - accuracy: 0.8340 - 50s/epoch - 63ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 50s - loss: 0.4504 - accuracy: 0.8340 - 50s/epoch - 63ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 50s - loss: 0.4501 - accuracy: 0.8340 - 50s/epoch - 63ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 50s - loss: 0.4503 - accuracy: 0.8340 - 50s/epoch - 62ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 51s - loss: 0.4537 - accuracy: 0.8334 - 51s/epoch - 64ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 50s - loss: 0.4504 - accuracy: 0.8342 - 50s/epoch - 63ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 50s - loss: 0.4501 - accuracy: 0.8342 - 50s/epoch - 63ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 50s - loss: 0.4501 - accuracy: 0.8342 - 50s/epoch - 63ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 50s - loss: 0.4499 - accuracy: 0.8342 - 50s/epoch - 63ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 50s - loss: 0.4498 - accuracy: 0.8343 - 50s/epoch - 63ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 51s - loss: 0.4545 - accuracy: 0.8328 - 51s/epoch - 64ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 50s - loss: 0.4514 - accuracy: 0.8336 - 50s/epoch - 63ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 50s - loss: 0.4508 - accuracy: 0.8336 - 50s/epoch - 63ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 50s - loss: 0.4511 - accuracy: 0.8336 - 50s/epoch - 63ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 50s - loss: 0.4510 - accuracy: 0.8336 - 50s/epoch - 63ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 50s - loss: 0.4509 - accuracy: 0.8336 - 50s/epoch - 63ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 51s - loss: 0.4539 - accuracy: 0.8330 - 51s/epoch - 64ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 51s - loss: 0.4507 - accuracy: 0.8340 - 51s/epoch - 64ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 51s - loss: 0.4503 - accuracy: 0.8341 - 51s/epoch - 65ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 50s - loss: 0.4501 - accuracy: 0.8341 - 50s/epoch - 63ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 50s - loss: 0.4501 - accuracy: 0.8341 - 50s/epoch - 63ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 50s - loss: 0.4501 - accuracy: 0.8341 - 50s/epoch - 63ms/step\n",
      "Epoch 1/6\n",
      "795/795 - 51s - loss: 0.4538 - accuracy: 0.8342 - 51s/epoch - 64ms/step\n",
      "Epoch 2/6\n",
      "795/795 - 50s - loss: 0.4499 - accuracy: 0.8342 - 50s/epoch - 63ms/step\n",
      "Epoch 3/6\n",
      "795/795 - 51s - loss: 0.4499 - accuracy: 0.8342 - 51s/epoch - 64ms/step\n",
      "Epoch 4/6\n",
      "795/795 - 53s - loss: 0.4500 - accuracy: 0.8343 - 53s/epoch - 67ms/step\n",
      "Epoch 5/6\n",
      "795/795 - 52s - loss: 0.4499 - accuracy: 0.8343 - 52s/epoch - 65ms/step\n",
      "Epoch 6/6\n",
      "795/795 - 50s - loss: 0.4499 - accuracy: 0.8343 - 50s/epoch - 64ms/step\n",
      "Epoch 1/3\n",
      "1193/1193 - 9s - loss: 0.3130 - accuracy: 0.8554 - 9s/epoch - 8ms/step\n",
      "Epoch 2/3\n",
      "1193/1193 - 8s - loss: 0.2828 - accuracy: 0.8647 - 8s/epoch - 7ms/step\n",
      "Epoch 3/3\n",
      "1193/1193 - 9s - loss: 0.2716 - accuracy: 0.8697 - 9s/epoch - 7ms/step\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x1188635b0>,\n",
       "             param_grid={'dropout': [0.1, 0.2], 'epochs': [3, 6],\n",
       "                         'max_len': [10, 100], 'max_tokens': [100, 1000]},\n",
       "             scoring='accuracy')"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "best_params = model.best_params_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "best_params"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'dropout': 0.1, 'epochs': 3, 'max_len': 10, 'max_tokens': 1000}"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "optimized_model = build_model(dropout = 0.1, max_len = 10, max_tokens = 1000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "optimized_model.fit(x_train, y_train, epochs = 3, validation_split = 0.2, callbacks = tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, verbose = 1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "954/954 [==============================] - 7s 8ms/step - loss: 0.2299 - accuracy: 0.8848 - val_loss: 0.3344 - val_accuracy: 0.8633\n",
      "Epoch 2/3\n",
      "954/954 [==============================] - 8s 8ms/step - loss: 0.2195 - accuracy: 0.8905 - val_loss: 0.3620 - val_accuracy: 0.8570\n",
      "Epoch 3/3\n",
      "954/954 [==============================] - 8s 8ms/step - loss: 0.2106 - accuracy: 0.8936 - val_loss: 0.3759 - val_accuracy: 0.8583\n",
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17d272d60>"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "optimized_model.evaluate(x_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "299/299 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8530\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.3918721079826355, 0.853024423122406]"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('toxic': conda)"
  },
  "interpreter": {
   "hash": "c0ac4971e360b0f2dea732e840eb0c9c41456636b7685f248e181635d8e4811b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}